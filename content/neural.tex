\newcommand{\cnn}{konvolúciós neurális hálózat}

\chapter{Konvolúciós Neurális Hálózatok}
Ebben a fejezetben bemutatom a \cnn ok (CNN) felépítését, használatát és néhány nevezetes modellt. A \cnn okat a legtöbb esetben képfeldolgozás terén használják. A projekt során is képfeldolgozást kell megvalósítani, így ezek ismerete elengedhetetlen.

\section{Szerkezet}
Egy alapvető \cnn nak három alkotóeleme van. Először a képen a konvolúciós rétegek 2D konvolúciót végeznek. Ezt a műveletet többször is elvégzi a hálózatok, a következő konvolúció bemenete mindig az előző kimenete lesz. Néhány konvolúció után a pooling következik. Ez a két művelet ismétlődhet többször is akár. Ezek után a teljesen összekötött réteg következik, ami a kimenetet állítja elő. Az itt bemutatott általános \cnn osztályozó funkciót tud leghatékonyabban megvalósítani.
% insert cnn.jpg and \cite{ConvNetExplain}

\subsection{Konvolúciós réteg}
Ebben a rétegben kétdimenziós konvolúciót végzünk a feldolgozandó képen. Ennek során először választunk egy kernelt. A kernel négyzetes mátrix, a képnél általában jóval kisebb mérettel. Gyakori kernelméret például a 3x3-as, vagy 5x5-ös mátrix. Alapvetően a kernel végighalad minden képkockán, és a középső pixelnek ad egy új értéket a kernel és a pixelek értékei alapján.

% Insert conv.drawio.pdf here

Vegyük például a következő 3x3-as kernelt és egy kép 5x5-ös részletét. Az ábrán bal oldalt található a kernel, középen a bemeneti kép, jobb oldalon pedig a kimeneti kép. A képnek a zölddel jelölt részét tudjuk csak leképezni anélkül, hogy a kernel kimutatna a képen kívülre. Ezen a területen a kernel közepét a egy számmal helyettesítjük. Ezt a számot úgy képezzük, hogy a kernel értékeit megszorozzuk az fedésben lévő pixellel, majd ezeket az értékeket összeadjuk. Az új képen a kernel közepét ezzel az értékkel helyettesítjük. Ezután eggyel jobbra toljuk a kernelt, a sorvéget elérve pedig a következő sor elejére helyezzük.

Sok esetben szeretnénk csökkenteni a képek méretér a konvolúció során, hogy gyorsítsuk a hálózatot. Ehhez a konvolúció stride paraméterét kell növelnünk. A stride alapesetben 1, és azt jelzi, hogy a művelet elvégzése után mennyivel toljuk arrébb a kernelt. Könnyen belátható, hogy minél nagyobb a stride, annál kevesebb lesz a kimeneti pixelek száma, így csökken a kép mérete.

Jellemzően több konvolúció történik egymás után. Az első ilyen réteg feladata az alacsony szintű elemek megtalálása, például élek vagy színváltások megkeresése. Ahogy egyre több konvolúció történik egymás után, a hálózat egyre magasabb szintű jellegzetességeket fog tudni felismerni. Így már ebben a fázisban is az emberi megértéshez hasonlóan dolgozza fel a képeket a neurális hálózat.
\cite{ConvNetExplain}

\subsection{Pooling réteg}
A pooling rétegek feladata a bemenetük méretbeli csökkentése. Nagyon hasonlóan működnek a konvolúciós rétegekhez, a pooling rétegekben is egy kernel iterál végig a képen. Jellemzően egynél nagyobb stride értékkel.

A különbség a kernel értékeiben mutatkozik leginkább. Kétféle pooling-ot fordul elő gyakran. Átlag pooling esetében a kernelt az általa fedett pixelek átlagával helyettesítjük, maximum pooling esetében pedig a fedett pixelek közül a legnagyobbal. A maximum pooling a leggyakrabban használt a kettő variáció közül.

A pooling lényege tulajdonképpen a képen található domináns sajátosságok kinyerése. Ezekről a részekről forgatásra és pozícióra nézve invariáns információt tárol el a hálózat.\cite{ConvNetExplain}

\subsection{Teljesen összekötött réteg}
A teljesen összekötött réteg bármilyen neurális hálózat alapvető építőeleme. Ha a művelet kimenete nem egy másik kép, hanem valamilyen szöveges információ, például a képen látható objektum klasszifikációja, akkor a teljesen összekötött réteg végzi el az osztályba sorolás műveletét.

% insert fcl.png with citation https://www.oreilly.com/library/view/tensorflow-for-deep/9781491980446/ch04.html

Ebben a rétegben két csoportba rendezve láthatunk neuronokat. A csoportok minden tagja össze van kötve a másik csoport összes tagjával és az összeköttetéseken súlyokat találunk. A képen a súlyokkal a vonalak vastagsága arányos. A jobb oldali csoport összes neuronja összegzi a bele futó élek végén található neuronok kimeneteit az éleken található értékekkel súlyozva, és az összeg lesz ennek a neuronnak a kimenete.

Ilyen rétegből is jellemzően több helyezkedik el egymás után. A legutolsó réteg a kimeneti réteg. Osztályozás esetén annyi kimeneti neuron van, ahány lehetséges osztály közül kell választani. Amelyik kimeneti neuronnak a legnagyobb az értéke, az ahhoz tartozó osztályba fogja sorolni a hálózat a bemeneti képet.

Felmerülhet kérdésként, hogy hogyan jutunk el egy képtől neuronokig. A kép a konvolúciós és pooling rétegekben folyamatosan egyre kisebb lesz méreteit tekintve. Egy ponton már olyan kicsi, hogy minden egyes pixelét tekinthetjük egy neuronnak, és felfoghatjuk a legelső teljesen összekötött réteg bemeneteként. A teljesen összekötött rétegek is jellemzően egymás után egyre kevesebb neuront tartalmaznak.

\section{Nevezetes neurális hálózat modellek}

% Szóveg, hogy a xilinx ad előre tanított hálókat

% válassz három szimpatikus hálőzatot
